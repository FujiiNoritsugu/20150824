{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FujiiNoritsugu/20150824/blob/master/docs/docs/integrations/vectorstores/google_vertex_ai_vector_search.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "655b8f55-2089-4733-8b09-35dea9580695",
      "metadata": {
        "id": "655b8f55-2089-4733-8b09-35dea9580695"
      },
      "source": [
        "# Google Vertex AI Vector Search\n",
        "\n",
        "This notebook shows how to use functionality related to the `Google Cloud Vertex AI Vector Search` vector database.\n",
        "\n",
        "> [Google Vertex AI Vector Search](https://cloud.google.com/vertex-ai/docs/vector-search/overview), formerly known as Vertex AI Matching Engine, provides the industry's leading high-scale low latency vector database. These vector databases are commonly referred to as vector similarity-matching or an approximate nearest neighbor (ANN) service.\n",
        "\n",
        "**Note**: Langchain API expects an endpoint and deployed index already created.Index creation time can take upto one hour.\n",
        "\n",
        "> To see how to create an index refer to the section [Create Index and deploy it to an Endpoint](#create-index-and-deploy-it-to-an-endpoint)  \n",
        "If you already have an index deployed , skip to [Create VectorStore from texts](#create-vector-store-from-texts)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aca99382",
      "metadata": {
        "id": "aca99382"
      },
      "source": [
        "## Create Index and deploy it to an Endpoint\n",
        "- This section demonstrates creating a new index and deploying it to an endpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35b5f3c5",
      "metadata": {
        "id": "35b5f3c5"
      },
      "outputs": [],
      "source": [
        "# TODO : Set values as per your requirements\n",
        "# Project and Storage Constants\n",
        "PROJECT_ID = \"gen-lang-client-0471694923\"\n",
        "REGION = \"<my_region>\"\n",
        "BUCKET = \"<my_gcs_bucket>\"\n",
        "BUCKET_URI = f\"gs://{BUCKET}\"\n",
        "\n",
        "# The number of dimensions for the textembedding-gecko@003 is 768\n",
        "# If other embedder is used, the dimensions would probably need to change.\n",
        "DIMENSIONS = 768\n",
        "\n",
        "# Index Constants\n",
        "DISPLAY_NAME = \"<my_matching_engine_index_id>\"\n",
        "DEPLOYED_INDEX_ID = \"<my_matching_engine_endpoint_id>\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce74ea7e",
      "metadata": {
        "id": "ce74ea7e"
      },
      "outputs": [],
      "source": [
        "# Create a bucket.\n",
        "! gsutil mb -l $REGION -p $PROJECT_ID $BUCKET_URI"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28d93078",
      "metadata": {
        "id": "28d93078"
      },
      "source": [
        "### Use [VertexAIEmbeddings](https://python.langchain.com/docs/integrations/text_embedding/google_vertex_ai_palm/) as the embeddings model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dfa92a08",
      "metadata": {
        "id": "dfa92a08"
      },
      "outputs": [],
      "source": [
        "from google.cloud import aiplatform\n",
        "from langchain_google_vertexai import VertexAIEmbeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58e5c762",
      "metadata": {
        "id": "58e5c762"
      },
      "outputs": [],
      "source": [
        "aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=BUCKET_URI)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c795913e",
      "metadata": {
        "id": "c795913e"
      },
      "outputs": [],
      "source": [
        "embedding_model = VertexAIEmbeddings(model_name=\"text-embedding-005\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73c2e7b5",
      "metadata": {
        "id": "73c2e7b5"
      },
      "source": [
        "### Create an empty Index"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b347e21",
      "metadata": {
        "id": "5b347e21"
      },
      "source": [
        "**Note :** While creating an index you should specify an \"index_update_method\" from either a \"BATCH_UPDATE\" or \"STREAM_UPDATE\"\n",
        "> A batch index is for when you want to update your index in a batch, with data which has been stored over a set amount of time, like systems which are processed weekly or monthly. A streaming index is when you want index data to be updated as new data is added to your datastore, for instance, if you have a bookstore and want to show new inventory online as soon as possible. Which type you choose is important, since setup and requirements are different.\n",
        "\n",
        "Refer [Official Documentation](https://cloud.google.com/vertex-ai/docs/vector-search/create-manage-index#create-index-batch) for more details on configuring indexes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37fdc7f1",
      "metadata": {
        "id": "37fdc7f1"
      },
      "outputs": [],
      "source": [
        "# NOTE : This operation can take upto 30 seconds\n",
        "my_index = aiplatform.MatchingEngineIndex.create_tree_ah_index(\n",
        "    display_name=DISPLAY_NAME,\n",
        "    dimensions=DIMENSIONS,\n",
        "    approximate_neighbors_count=150,\n",
        "    distance_measure_type=\"DOT_PRODUCT_DISTANCE\",\n",
        "    index_update_method=\"STREAM_UPDATE\",  # allowed values BATCH_UPDATE , STREAM_UPDATE\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1723d40a",
      "metadata": {
        "id": "1723d40a"
      },
      "source": [
        "### Create an Endpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4059888",
      "metadata": {
        "id": "f4059888"
      },
      "outputs": [],
      "source": [
        "# Create an endpoint\n",
        "my_index_endpoint = aiplatform.MatchingEngineIndexEndpoint.create(\n",
        "    display_name=f\"{DISPLAY_NAME}-endpoint\", public_endpoint_enabled=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43a85682",
      "metadata": {
        "id": "43a85682"
      },
      "source": [
        "### Deploy Index to the Endpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6582ec1",
      "metadata": {
        "id": "a6582ec1"
      },
      "outputs": [],
      "source": [
        "# NOTE : This operation can take upto 20 minutes\n",
        "my_index_endpoint = my_index_endpoint.deploy_index(\n",
        "    index=my_index, deployed_index_id=DEPLOYED_INDEX_ID\n",
        ")\n",
        "\n",
        "my_index_endpoint.deployed_indexes"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9971578-0ae9-4809-9e80-e5f9d3dcc98a",
      "metadata": {
        "id": "a9971578-0ae9-4809-9e80-e5f9d3dcc98a"
      },
      "source": [
        "## Create Vector Store from texts"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d98d379",
      "metadata": {
        "id": "4d98d379"
      },
      "source": [
        "NOTE : If you have existing Index and Endpoints, you can load them using below code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "066c0f63",
      "metadata": {
        "id": "066c0f63"
      },
      "outputs": [],
      "source": [
        "# TODO : replace 1234567890123456789 with your acutial index ID\n",
        "my_index = aiplatform.MatchingEngineIndex(\"1234567890123456789\")\n",
        "\n",
        "# TODO : replace 1234567890123456789 with your acutial endpoint ID\n",
        "my_index_endpoint = aiplatform.MatchingEngineIndexEndpoint(\"1234567890123456789\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7c96da4-8d97-4f69-8c13-d2fcafc03b05",
      "metadata": {
        "id": "f7c96da4-8d97-4f69-8c13-d2fcafc03b05"
      },
      "outputs": [],
      "source": [
        "from langchain_google_vertexai import (\n",
        "    VectorSearchVectorStore,\n",
        "    VectorSearchVectorStoreDatastore,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b25a61eb",
      "metadata": {
        "id": "b25a61eb"
      },
      "source": [
        "![Langchainassets.png](attachment:Langchainassets.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97ac49ae",
      "metadata": {
        "id": "97ac49ae"
      },
      "source": [
        "### Create simple vectorstore ( without filters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58b70880-edd9-46f3-b769-f26c2bcc8395",
      "metadata": {
        "id": "58b70880-edd9-46f3-b769-f26c2bcc8395"
      },
      "outputs": [],
      "source": [
        "# Input texts\n",
        "texts = [\n",
        "    \"The cat sat on\",\n",
        "    \"the mat.\",\n",
        "    \"I like to\",\n",
        "    \"eat pizza for\",\n",
        "    \"dinner.\",\n",
        "    \"The sun sets\",\n",
        "    \"in the west.\",\n",
        "]\n",
        "\n",
        "# Create a Vector Store\n",
        "vector_store = VectorSearchVectorStore.from_components(\n",
        "    project_id=PROJECT_ID,\n",
        "    region=REGION,\n",
        "    gcs_bucket_name=BUCKET,\n",
        "    index_id=my_index.name,\n",
        "    endpoint_id=my_index_endpoint.name,\n",
        "    embedding=embedding_model,\n",
        "    stream_update=True,\n",
        ")\n",
        "\n",
        "# Add vectors and mapped text chunks to your vectore store\n",
        "vector_store.add_texts(texts=texts)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "080cbbdc",
      "metadata": {
        "id": "080cbbdc"
      },
      "source": [
        "### OPTIONAL : You can also create vectore and store chunks in a Datastore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97ef5dfd",
      "metadata": {
        "id": "97ef5dfd"
      },
      "outputs": [],
      "source": [
        "# NOTE : This operation can take upto 20 mins\n",
        "vector_store = VectorSearchVectorStoreDatastore.from_components(\n",
        "    project_id=PROJECT_ID,\n",
        "    region=REGION,\n",
        "    index_id=my_index.name,\n",
        "    endpoint_id=my_index_endpoint.name,\n",
        "    embedding=embedding_model,\n",
        "    stream_update=True,\n",
        ")\n",
        "\n",
        "vector_store.add_texts(texts=texts, is_complete_overwrite=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7c65716",
      "metadata": {
        "id": "b7c65716"
      },
      "outputs": [],
      "source": [
        "# Try running a simialarity search\n",
        "vector_store.similarity_search(\"pizza\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65d92635",
      "metadata": {
        "id": "65d92635"
      },
      "source": [
        "### Create vectorstore with metadata filters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "986951f7",
      "metadata": {
        "id": "986951f7"
      },
      "outputs": [],
      "source": [
        "# Input text with metadata\n",
        "record_data = [\n",
        "    {\n",
        "        \"description\": \"A versatile pair of dark-wash denim jeans.\"\n",
        "        \"Made from durable cotton with a classic straight-leg cut, these jeans\"\n",
        "        \" transition easily from casual days to dressier occasions.\",\n",
        "        \"price\": 65.00,\n",
        "        \"color\": \"blue\",\n",
        "        \"season\": [\"fall\", \"winter\", \"spring\"],\n",
        "    },\n",
        "    {\n",
        "        \"description\": \"A lightweight linen button-down shirt in a crisp white.\"\n",
        "        \" Perfect for keeping cool with breathable fabric and a relaxed fit.\",\n",
        "        \"price\": 34.99,\n",
        "        \"color\": \"white\",\n",
        "        \"season\": [\"summer\", \"spring\"],\n",
        "    },\n",
        "    {\n",
        "        \"description\": \"A soft, chunky knit sweater in a vibrant forest green. \"\n",
        "        \"The oversized fit and cozy wool blend make this ideal for staying warm \"\n",
        "        \"when the temperature drops.\",\n",
        "        \"price\": 89.99,\n",
        "        \"color\": \"green\",\n",
        "        \"season\": [\"fall\", \"winter\"],\n",
        "    },\n",
        "    {\n",
        "        \"description\": \"A classic crewneck t-shirt in a soft, heathered blue. \"\n",
        "        \"Made from comfortable cotton jersey, this t-shirt is a wardrobe essential \"\n",
        "        \"that works for every season.\",\n",
        "        \"price\": 19.99,\n",
        "        \"color\": \"blue\",\n",
        "        \"season\": [\"fall\", \"winter\", \"summer\", \"spring\"],\n",
        "    },\n",
        "    {\n",
        "        \"description\": \"A flowing midi-skirt in a delicate floral print. \"\n",
        "        \"Lightweight and airy, this skirt adds a touch of feminine style \"\n",
        "        \"to warmer days.\",\n",
        "        \"price\": 45.00,\n",
        "        \"color\": \"white\",\n",
        "        \"season\": [\"spring\", \"summer\"],\n",
        "    },\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6cd5fba1",
      "metadata": {
        "id": "6cd5fba1"
      },
      "outputs": [],
      "source": [
        "# Parse and prepare input data\n",
        "\n",
        "texts = []\n",
        "metadatas = []\n",
        "for record in record_data:\n",
        "    record = record.copy()\n",
        "    page_content = record.pop(\"description\")\n",
        "    texts.append(page_content)\n",
        "    if isinstance(page_content, str):\n",
        "        metadata = {**record}\n",
        "        metadatas.append(metadata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc6f0e08",
      "metadata": {
        "id": "fc6f0e08"
      },
      "outputs": [],
      "source": [
        "# Inspect metadatas\n",
        "metadatas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb993e1a",
      "metadata": {
        "id": "eb993e1a"
      },
      "outputs": [],
      "source": [
        "# NOTE : This operation can take more than 20 mins\n",
        "vector_store = VectorSearchVectorStore.from_components(\n",
        "    project_id=PROJECT_ID,\n",
        "    region=REGION,\n",
        "    gcs_bucket_name=BUCKET,\n",
        "    index_id=my_index.name,\n",
        "    endpoint_id=my_index_endpoint.name,\n",
        "    embedding=embedding_model,\n",
        ")\n",
        "\n",
        "vector_store.add_texts(texts=texts, metadatas=metadatas, is_complete_overwrite=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dac171b9",
      "metadata": {
        "id": "dac171b9"
      },
      "outputs": [],
      "source": [
        "from google.cloud.aiplatform.matching_engine.matching_engine_index_endpoint import (\n",
        "    Namespace,\n",
        "    NumericNamespace,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03ed6710",
      "metadata": {
        "id": "03ed6710"
      },
      "outputs": [],
      "source": [
        "# Try running a simple similarity search\n",
        "\n",
        "# Below code should return 5 results\n",
        "vector_store.similarity_search(\"shirt\", k=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d084f0e7",
      "metadata": {
        "id": "d084f0e7"
      },
      "outputs": [],
      "source": [
        "# Try running a similarity search with text filter\n",
        "filters = [Namespace(name=\"season\", allow_tokens=[\"spring\"])]\n",
        "\n",
        "# Below code should return 4 results now\n",
        "vector_store.similarity_search(\"shirt\", k=5, filter=filters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3eb3206e",
      "metadata": {
        "id": "3eb3206e"
      },
      "outputs": [],
      "source": [
        "# Try running a similarity search with combination of text and numeric filter\n",
        "filters = [Namespace(name=\"season\", allow_tokens=[\"spring\"])]\n",
        "numeric_filters = [NumericNamespace(name=\"price\", value_float=40.0, op=\"LESS\")]\n",
        "\n",
        "# Below code should return 2 results now\n",
        "vector_store.similarity_search(\n",
        "    \"shirt\", k=5, filter=filters, numeric_filter=numeric_filters\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4de820b3",
      "metadata": {
        "id": "4de820b3"
      },
      "source": [
        "### Use Vector Store as retriever"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ebe598e",
      "metadata": {
        "id": "0ebe598e"
      },
      "outputs": [],
      "source": [
        "# Initialize the vectore_store as retriever\n",
        "retriever = vector_store.as_retriever()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98a251b1",
      "metadata": {
        "id": "98a251b1"
      },
      "outputs": [],
      "source": [
        "# perform simple similarity search on retriever\n",
        "retriever.invoke(\"What are my options in breathable fabric?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61ab5631",
      "metadata": {
        "id": "61ab5631"
      },
      "outputs": [],
      "source": [
        "# Try running a similarity search with text filter\n",
        "filters = [Namespace(name=\"season\", allow_tokens=[\"spring\"])]\n",
        "\n",
        "retriever.search_kwargs = {\"filter\": filters}\n",
        "\n",
        "# perform similarity search with filters on retriever\n",
        "retriever.invoke(\"What are my options in breathable fabric?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5bfcec72",
      "metadata": {
        "id": "5bfcec72"
      },
      "outputs": [],
      "source": [
        "# Try running a similarity search with combination of text and numeric filter\n",
        "filters = [Namespace(name=\"season\", allow_tokens=[\"spring\"])]\n",
        "numeric_filters = [NumericNamespace(name=\"price\", value_float=40.0, op=\"LESS\")]\n",
        "\n",
        "\n",
        "retriever.search_kwargs = {\"filter\": filters, \"numeric_filter\": numeric_filters}\n",
        "\n",
        "retriever.invoke(\"What are my options in breathable fabric?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2def7692",
      "metadata": {
        "id": "2def7692"
      },
      "source": [
        "### Use filters with retriever in Question Answering Chains"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0f6e31c",
      "metadata": {
        "id": "a0f6e31c"
      },
      "outputs": [],
      "source": [
        "from langchain_google_vertexai import VertexAI\n",
        "\n",
        "llm = VertexAI(model_name=\"gemini-pro\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e9054c1",
      "metadata": {
        "id": "6e9054c1"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "filters = [Namespace(name=\"season\", allow_tokens=[\"spring\"])]\n",
        "numeric_filters = [NumericNamespace(name=\"price\", value_float=40.0, op=\"LESS\")]\n",
        "\n",
        "retriever.search_kwargs = {\"k\": 2, \"filter\": filters, \"numeric_filter\": numeric_filters}\n",
        "\n",
        "retrieval_qa = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=retriever,\n",
        "    return_source_documents=True,\n",
        ")\n",
        "\n",
        "question = \"What are my options in breathable fabric?\"\n",
        "response = retrieval_qa({\"query\": question})\n",
        "print(f\"{response['result']}\")\n",
        "print(\"REFERENCES\")\n",
        "print(f\"{response['source_documents']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e987ddef",
      "metadata": {
        "id": "e987ddef"
      },
      "source": [
        "## Read , Chunk , Vectorise and Index PDFs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77675a97",
      "metadata": {
        "id": "77675a97"
      },
      "outputs": [],
      "source": [
        "!pip install pypdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aad1896b",
      "metadata": {
        "id": "aad1896b"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0454681b",
      "metadata": {
        "id": "0454681b"
      },
      "outputs": [],
      "source": [
        "loader = PyPDFLoader(\"https://arxiv.org/pdf/1706.03762.pdf\")\n",
        "pages = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "159e5722",
      "metadata": {
        "id": "159e5722"
      },
      "outputs": [],
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    # Set a really small chunk size, just to show.\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=20,\n",
        "    length_function=len,\n",
        "    is_separator_regex=False,\n",
        ")\n",
        "doc_splits = text_splitter.split_documents(pages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a598ec8",
      "metadata": {
        "id": "5a598ec8"
      },
      "outputs": [],
      "source": [
        "texts = [doc.page_content for doc in doc_splits]\n",
        "metadatas = [doc.metadata for doc in doc_splits]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4dc880d6",
      "metadata": {
        "id": "4dc880d6"
      },
      "outputs": [],
      "source": [
        "texts[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "558f9495",
      "metadata": {
        "id": "558f9495"
      },
      "outputs": [],
      "source": [
        "# Inspect Metadata of 1st page\n",
        "metadatas[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81143e4b",
      "metadata": {
        "id": "81143e4b"
      },
      "outputs": [],
      "source": [
        "vector_store = VectorSearchVectorStore.from_components(\n",
        "    project_id=PROJECT_ID,\n",
        "    region=REGION,\n",
        "    gcs_bucket_name=BUCKET,\n",
        "    index_id=my_index.name,\n",
        "    endpoint_id=my_index_endpoint.name,\n",
        "    embedding=embedding_model,\n",
        ")\n",
        "\n",
        "vector_store.add_texts(texts=texts, metadatas=metadatas, is_complete_overwrite=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7557d531",
      "metadata": {
        "id": "7557d531"
      },
      "outputs": [],
      "source": [
        "vector_store = VectorSearchVectorStore.from_components(\n",
        "    project_id=PROJECT_ID,\n",
        "    region=REGION,\n",
        "    gcs_bucket_name=BUCKET,\n",
        "    index_id=my_index.name,\n",
        "    endpoint_id=my_index_endpoint.name,\n",
        "    embedding=embedding_model,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31222b03",
      "metadata": {
        "id": "31222b03"
      },
      "source": [
        "## Hybrid Search"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8a308f2",
      "metadata": {
        "id": "b8a308f2"
      },
      "source": [
        "Vector Search supports hybrid search, a popular architecture pattern in information retrieval (IR) that combines both semantic search and keyword search (also called token-based search). With hybrid search, developers can take advantage of the best of the two approaches, effectively providing higher search quality.\n",
        "Click [here](https://cloud.google.com/vertex-ai/docs/vector-search/about-hybrid-search) to learn more.\n",
        "\n",
        "In order to use hybrid search, we need to fit a sparse embedding vectorizer and handle the embeddings outside of the Vector Search integration.\n",
        "An example of sparse embedding vectorizer is sklearn TfidfVectorizer but other techniques can be used, for instance BM25."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e319402d",
      "metadata": {
        "id": "e319402d"
      },
      "outputs": [],
      "source": [
        "# Define some sample data\n",
        "texts = [\n",
        "    \"The cat sat on\",\n",
        "    \"the mat.\",\n",
        "    \"I like to\",\n",
        "    \"eat pizza for\",\n",
        "    \"dinner.\",\n",
        "    \"The sun sets\",\n",
        "    \"in the west.\",\n",
        "]\n",
        "\n",
        "# optional IDs\n",
        "ids = [\"i_\" + str(i + 1) for i in range(len(texts))]\n",
        "\n",
        "# optional metadata\n",
        "metadatas = [{\"my_metadata\": i} for i in range(len(texts))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14efefc1",
      "metadata": {
        "id": "14efefc1"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Fit the TFIDF Vectorizer (This is usually done on a very large corpus of data to make sure that word statistics generalize well on new data)\n",
        "vectorizer = TfidfVectorizer()\n",
        "vectorizer.fit(texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c7206c2",
      "metadata": {
        "id": "2c7206c2"
      },
      "outputs": [],
      "source": [
        "# Utility function to transform text into a TF-IDF Sparse Vector\n",
        "def get_sparse_embedding(tfidf_vectorizer, text):\n",
        "    tfidf_vector = tfidf_vectorizer.transform([text])\n",
        "    values = []\n",
        "    dims = []\n",
        "    for i, tfidf_value in enumerate(tfidf_vector.data):\n",
        "        values.append(float(tfidf_value))\n",
        "        dims.append(int(tfidf_vector.indices[i]))\n",
        "    return {\"values\": values, \"dimensions\": dims}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0dc5b782",
      "metadata": {
        "id": "0dc5b782"
      },
      "outputs": [],
      "source": [
        "# semantic (dense) embeddings\n",
        "embeddings = embedding_model.embed_documents(texts)\n",
        "# tfidf (sparse) embeddings\n",
        "sparse_embeddings = [get_sparse_embedding(vectorizer, x) for x in texts]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a353679",
      "metadata": {
        "id": "3a353679"
      },
      "outputs": [],
      "source": [
        "sparse_embeddings[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2623cad9",
      "metadata": {
        "id": "2623cad9"
      },
      "outputs": [],
      "source": [
        "# Add the dense and sparse embeddings in Vector Search\n",
        "\n",
        "vector_store.add_texts_with_embeddings(\n",
        "    texts=texts,\n",
        "    embeddings=embeddings,\n",
        "    sparse_embeddings=sparse_embeddings,\n",
        "    ids=ids,\n",
        "    metadatas=metadatas,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29885e38",
      "metadata": {
        "id": "29885e38"
      },
      "outputs": [],
      "source": [
        "# Run hybrid search\n",
        "query = \"the cat\"\n",
        "embedding = embedding_model.embed_query(query)\n",
        "sparse_embedding = get_sparse_embedding(vectorizer, query)\n",
        "\n",
        "vector_store.similarity_search_by_vector_with_score(\n",
        "    embedding=embedding,\n",
        "    sparse_embedding=sparse_embedding,\n",
        "    k=5,\n",
        "    rrf_ranking_alpha=0.7,  # 0.7 weight to dense and 0.3 weight to sparse\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "environment": {
      "kernel": "python3",
      "name": "common-cpu.m107",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/base-cpu:m107"
    },
    "kernelspec": {
      "display_name": "langchain-google-community-3Os9yvMd-py3.10",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}